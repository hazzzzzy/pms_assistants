import json
import logging
from typing import Annotated, Literal, TypedDict

import tiktoken
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, trim_messages, ToolMessage, AIMessage
from langgraph.constants import END
from langgraph.graph import StateGraph, add_messages
from langgraph.prebuilt import ToolNode

from core.agent_context import AgentContext
from core.agent_prompt import AGENT_SYSTEM_PROMPT, CHAT_SYSTEM_PROMPT, ROUTER_PROMPT, SUMMARY_SYSTEM_PROMPT
from core.agent_tools import pms_query_mysql, pms_search_vector
from schemas.pms_agent_schema import parse_route
from utils.utils import get_valid_json

logger = logging.getLogger(__name__)


class AgentState(TypedDict):
    # add_messages æ˜¯ LangGraph çš„é»‘é­”æ³•ï¼š
    # å½“èŠ‚ç‚¹è¿”å›æ–°çš„ message æ—¶ï¼Œå®ƒä¸æ˜¯è¦†ç›–ï¼Œè€Œæ˜¯ appendï¼ˆè¿½åŠ ï¼‰åˆ°åˆ—è¡¨é‡Œ
    messages: Annotated[list[BaseMessage], add_messages]
    next_node: str


class AgentInstance:
    def __init__(self, llm: BaseChatModel):
        self.llm = llm
        # self.llm = ChatDeepSeek(model="deepseek-chat", temperature=0.1)
        self.llm_with_tools = None

    def init_tools_and_llm(self, ctx: AgentContext):
        tools = [pms_query_mysql, pms_search_vector(ctx)]
        self.llm_with_tools = self.llm.bind_tools(tools)
        return tools

    def use_trimmer(self, messages):
        system_message = [m for m in messages if isinstance(m, SystemMessage)]
        other_messages = [m for m in messages if not isinstance(m, SystemMessage)]

        question = None
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                question = msg
                break

        trimmed_messages = trim_messages(
            other_messages,
            strategy="last",
            token_counter=self.count_tokens,
            # token_counter=len,
            max_tokens=6000,
            include_system=False,
            # ç¡®ä¿å¯¹è¯ä» Human å¼€å§‹
            # start_on="human",
            # å…è®¸éƒ¨åˆ†ä¿®å‰ªï¼ˆé€šå¸¸è®¾ä¸º False ä»¥ä¿è¯å®Œæ•´æ€§ï¼‰
            allow_partial=False
        )

        valid_messages = []
        active_tool_call_ids = set()
        for i, msg in enumerate(trimmed_messages):
            if isinstance(msg, AIMessage):
                if msg.tool_calls:
                    if i + 1 < len(trimmed_messages):
                        next_msg = trimmed_messages[i + 1]
                        current_tool_call_ids = {call['id'] for call in msg.tool_calls}
                        if isinstance(next_msg, ToolMessage):
                            if next_msg.tool_call_id in current_tool_call_ids:
                                valid_messages.append(msg)
                                active_tool_call_ids = current_tool_call_ids
                else:
                    valid_messages.append(msg)
            elif isinstance(msg, ToolMessage):
                if msg.tool_call_id in active_tool_call_ids:
                    valid_messages.append(msg)
            elif isinstance(msg, HumanMessage):
                valid_messages.append(msg)
                if isinstance(msg, HumanMessage):
                    active_tool_call_ids = set()

        if question and question not in valid_messages:
            valid_messages = [question, *valid_messages]

        return system_message + valid_messages

    async def chat_node(self, state: AgentState):
        messages = state['messages']
        messages = [m for m in messages if not isinstance(m, SystemMessage)]
        messages = [SystemMessage(content=CHAT_SYSTEM_PROMPT), *messages]

        messages_without_tool = []
        for msg in messages:
            if isinstance(msg, ToolMessage):
                continue
            elif isinstance(msg, AIMessage) and msg.tool_calls:
                continue
            else:
                messages_without_tool.append(msg)

        clean_messages = self.use_trimmer(messages_without_tool)

        response = await self.llm.ainvoke(clean_messages)
        self.print_message(clean_messages + [response])
        return {"messages": [response]}

    async def router_node(self, state: AgentState):
        needed_messages = []
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                content = msg.content or ""
                marker = "ç”¨æˆ·é—®é¢˜ï¼š"
                if marker in content:
                    content = content.split(marker, 1)[-1].strip()
                needed_messages.append(HumanMessage(content=content))
            elif isinstance(msg, AIMessage):
                if not msg.tool_calls:
                    needed_messages.append(msg)

            if len(needed_messages) >= 3:
                break
        resp = await self.llm.ainvoke([SystemMessage(content=ROUTER_PROMPT), *reversed(needed_messages)])

        parsed = parse_route((resp.content or "").strip())
        if not parsed:
            # é‡è¯•ä¸€æ¬¡ï¼šæ›´å¼ºçº¦æŸ
            resp2 = await self.llm.ainvoke([SystemMessage(content=ROUTER_PROMPT + "\nå†æ¬¡å¼ºè°ƒï¼šåªèƒ½è¾“å‡º JSONã€‚"), *reversed(needed_messages)])
            parsed = parse_route((resp2.content or "").strip())

        if not parsed:
            return {"next_node": "chat_agent"}  # å›é€€

        return {"next_node": "rag_sql_agent" if parsed.route == "SQL" else "chat_agent"}

    async def agent_node(self, state: AgentState):
        messages = state["messages"]
        messages = [m for m in messages if not isinstance(m, SystemMessage)]
        messages = [SystemMessage(content=AGENT_SYSTEM_PROMPT), *messages]

        clean_messages = self.use_trimmer(messages)
        response = await self.llm_with_tools.ainvoke(clean_messages)
        if response.response_metadata.get('finish_reason') == 'stop':
            self.print_message(clean_messages + [response])

        return {"messages": [response]}

    async def summarize_node(self, state: AgentState):
        # å–æœ€åä¸€ä¸ªç”¨æˆ·é—®é¢˜
        question = None
        for m in reversed(state["messages"]):
            if isinstance(m, HumanMessage):
                question = m.content
                break

        # å– SQL Agent æœ€åä¸€æ¬¡â€œétool_callsâ€çš„ AIMessage ä½œä¸ºä¸­é—´JSON
        payload = None
        for m in reversed(state["messages"]):
            m_content = (m.content or '').strip()
            if isinstance(m, AIMessage) and not m.tool_calls and m_content:
                logger.warning(f'å›ç­”ï¼š{m_content}')
                payload = get_valid_json(m_content)
                logger.warning(f'è§£æå†…å®¹ï¼š{payload}')
                break

        if not payload or not isinstance(payload, dict):
            # ä¸­é—´ç»“æœç¼ºå¤±ï¼ŒæŒ‰å¤±è´¥å¤„ç†
            return {"messages": [AIMessage(content="æš‚æ— ç›¸å…³æ•°æ®ï¼Œè¯·ç‚¹å‡»æ¶ˆæ¯ä¸‹æ–¹ğŸ‘ï¸åé¦ˆç»™æˆ‘ä»¬")]}

        inp = [
            SystemMessage(content=SUMMARY_SYSTEM_PROMPT),
            HumanMessage(content=f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\nä¸­é—´æ•°æ®ï¼š{json.dumps(payload, ensure_ascii=False)}")
        ]
        resp = await self.llm.ainvoke(inp)
        return {"messages": [resp]}

    @staticmethod
    def should_continue(state: AgentState) -> Literal["tools", "summarize"]:
        last_message = state["messages"][-1]
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            return "tools"
        return "summarize"

    def build(self, ctx: AgentContext, checkpointer=None):
        tools = self.init_tools_and_llm(ctx)
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("rag_sql_agent", self.agent_node)
        workflow.add_node("chat_agent", self.chat_node)
        workflow.add_node("router", self.router_node)
        workflow.add_node("summarize", self.summarize_node)

        tool_node = ToolNode(tools)
        workflow.add_node("tools", tool_node)

        workflow.set_entry_point("router")
        workflow.add_conditional_edges(
            "router",
            lambda state: state["next_node"],  # è¯»å– next_node å­—æ®µ
            {
                "rag_sql_agent": "rag_sql_agent",
                "chat_agent": "chat_agent"
            }
        )
        workflow.add_conditional_edges(
            "rag_sql_agent",
            self.should_continue,
            {"tools": "tools", "summarize": "summarize"}
        )
        workflow.add_edge("tools", "rag_sql_agent")
        workflow.add_edge("chat_agent", END)
        workflow.add_edge("summarize", END)

        app = workflow.compile(checkpointer=checkpointer)
        return app

    @staticmethod
    def count_tokens(messages: list[BaseMessage]) -> int:
        """
        ä½¿ç”¨ cl100k_base (GPT-4æ ‡å‡†) ä¼°ç®— DeepSeek çš„ Token æ•°
        """
        encoding = tiktoken.get_encoding("cl100k_base")
        num_tokens = 0
        for m in messages:
            # æ¯æ¡æ¶ˆæ¯çš„åŸºç¡€å¼€é”€ (OpenAI æ ‡å‡†é€šå¸¸æ˜¯ 3 token: <|start|>, role, <|end|>)
            num_tokens += 3

            # è®¡ç®—å†…å®¹çš„ token
            # æ³¨æ„ï¼šè¿™é‡Œè¦åšä¸ªåˆ¤ç©ºï¼Œå› ä¸ºæœ‰äº› ToolMessage content å¯èƒ½æ˜¯ None
            content = m.content or ""
            num_tokens += len(encoding.encode(str(content)))

            # å¦‚æœæœ‰ tool_calls (AI æ­£åœ¨å‘¼å«å·¥å…·)ï¼Œè¿™äº›ä¹Ÿè¦ç®— token
            if hasattr(m, "tool_calls") and m.tool_calls:
                for tool_call in m.tool_calls:
                    # ç®€å•ä¼°ç®—ï¼šå‡½æ•°å + å‚æ•° json çš„é•¿åº¦
                    num_tokens += len(encoding.encode(str(tool_call)))

        return num_tokens

    @staticmethod
    def print_message(msg_list):
        for i, msg in enumerate(msg_list):
            msg_type = msg.type.upper()
            logger.info(f'*****************[{i + 1}]  {msg_type}*******************')

            content = msg.content
            tool_calls = hasattr(msg, "tool_calls")
            if isinstance(msg, AIMessage):
                if len(content) > 1:
                    logger.info(msg)
                if tool_calls and len(msg.tool_calls) > 0:
                    logger.info(f"è°ƒç”¨å·¥å…·{msg.tool_calls[0]['name']}: {msg.tool_calls}")
            elif isinstance(msg, ToolMessage):
                logger.info(msg)
            else:
                logger.info(f"{content[:200]}...")
